{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train the convolutional neural network:\n",
    "We require the following folders:\n",
    "- DataFiltered: contains the filtered data by class and augmented (see filter.ipynb)\n",
    "- labels_upsampled.csv: contains the labels of the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we first do is filter the data into training, test and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Frank\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import PIL\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter the data into train/val/test in ratio 80|10|10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>item_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100_i110.png</td>\n",
       "      <td>100</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100_i120.png</td>\n",
       "      <td>100</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100_i130.png</td>\n",
       "      <td>100</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100_i140.png</td>\n",
       "      <td>100</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100_i150.png</td>\n",
       "      <td>100</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19639</th>\n",
       "      <td>362_i110_aug_x1995.png</td>\n",
       "      <td>362</td>\n",
       "      <td>wood,paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19640</th>\n",
       "      <td>485_i190_aug296_aug_x1996.png</td>\n",
       "      <td>485</td>\n",
       "      <td>wood,paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19641</th>\n",
       "      <td>29_i160_aug_x1997.png</td>\n",
       "      <td>29</td>\n",
       "      <td>wood,paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19642</th>\n",
       "      <td>868_i140_aug2368_aug_x1998.png</td>\n",
       "      <td>868</td>\n",
       "      <td>wood,paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19643</th>\n",
       "      <td>26_i130_aug2690_aug_x1999.png</td>\n",
       "      <td>26</td>\n",
       "      <td>wood,paper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19644 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             filename  item_type       label\n",
       "0                        100_i110.png        100     plastic\n",
       "1                        100_i120.png        100     plastic\n",
       "2                        100_i130.png        100     plastic\n",
       "3                        100_i140.png        100     plastic\n",
       "4                        100_i150.png        100     plastic\n",
       "...                               ...        ...         ...\n",
       "19639          362_i110_aug_x1995.png        362  wood,paper\n",
       "19640   485_i190_aug296_aug_x1996.png        485  wood,paper\n",
       "19641           29_i160_aug_x1997.png         29  wood,paper\n",
       "19642  868_i140_aug2368_aug_x1998.png        868  wood,paper\n",
       "19643   26_i130_aug2690_aug_x1999.png         26  wood,paper\n",
       "\n",
       "[19644 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeling = pd.read_csv('./labels_upsampled.csv')\n",
    "labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_item_type = labeling['item_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_shuffle = np.random.permutation(unique_item_type)\n",
    "train_item_type = item_shuffle[:int(len(item_shuffle)*0.8)]\n",
    "test_item_type = item_shuffle[int(len(item_shuffle)*0.8):int(len(item_shuffle)*0.9)]\n",
    "val_item_type = item_shuffle[int(len(item_shuffle)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = './DataFilteredPlural/'\n",
    "target_dir = './trainvaltest/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the target directory if it exists\n",
    "if (os.path.exists(target_dir)):\n",
    "    shutil.rmtree(target_dir)\n",
    "\n",
    "#make the target directory\n",
    "os.mkdir(target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy files into train/val/test based on split\n",
    "if (not os.path.exists(target_dir + \"train\") and not os.path.exists(target_dir + \"val\") and not os.path.exists(target_dir + \"test\")):\n",
    "    os.mkdir(target_dir + \"train\")\n",
    "    os.mkdir(target_dir + \"val\")\n",
    "    os.mkdir(target_dir + \"test\")\n",
    "\n",
    "for item in train_item_type:\n",
    "    list_item = labeling[labeling['item_type'] == item]\n",
    "    for index, row in list_item.iterrows():\n",
    "        #print(source_dir + row['filename'])\n",
    "        shutil.copy(source_dir + row['filename'], target_dir + \"train/\" + row['filename'])\n",
    "\n",
    "for item in val_item_type:\n",
    "    list_item = labeling[labeling['item_type'] == item]\n",
    "    for index, row in list_item.iterrows():\n",
    "        #print(source_dir + row['filename'])\n",
    "        shutil.copy(source_dir + row['filename'], target_dir + \"val/\" + row['filename'])\n",
    "\n",
    "for item in test_item_type:\n",
    "    list_item = labeling[labeling['item_type'] == item]\n",
    "    for index, row in list_item.iterrows():\n",
    "        #print(source_dir + row['filename'])\n",
    "        shutil.copy(source_dir + row['filename'], target_dir + \"test/\" + row['filename'])\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training via Convolutional Neural Network:\n",
    "But first we need to load the data into dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency of each class in train/val/test\n",
    "train_freq = {\"metal\": 0, \"plastic\": 0, \"wood,paper\": 0}\n",
    "val_freq = {\"metal\": 0, \"plastic\": 0, \"wood,paper\": 0}\n",
    "test_freq = {\"metal\": 0, \"plastic\": 0, \"wood,paper\": 0}\n",
    "\n",
    "for file in os.listdir(target_dir + \"train\"):\n",
    "    material_type = labeling[labeling['filename'] == file]['label'].values[0]\n",
    "    train_freq[material_type] += 1\n",
    "for file in os.listdir(target_dir + \"val\"):\n",
    "    material_type = labeling[labeling['filename'] == file]['label'].values[0]\n",
    "    val_freq[material_type] += 1\n",
    "for file in os.listdir(target_dir + \"test\"):\n",
    "    material_type = labeling[labeling['filename'] == file]['label'].values[0]\n",
    "    test_freq[material_type] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot frequency of each class in train/val/test\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.bar(train_freq.keys(), train_freq.values())\n",
    "plt.title(\"Train\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.bar(val_freq.keys(), val_freq.values())\n",
    "plt.title(\"Val\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.bar(test_freq.keys(), test_freq.values())\n",
    "plt.title(\"Test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the factor to balance the dataset\n",
    "ratio = 1/3\n",
    "metal_factor = 1 / (train_freq[\"metal\"]) * len(os.listdir(target_dir + \"train\")) * ratio\n",
    "plastic_factor = 1 / (train_freq[\"plastic\"]) * len(os.listdir(target_dir + \"train\")) * ratio\n",
    "wood_paper_factor = 1 / (train_freq[\"wood,paper\"]) * len(os.listdir(target_dir + \"train\")) * ratio\n",
    "print(\"metal_factor: \", metal_factor)\n",
    "print(\"plastic_factor: \", plastic_factor)\n",
    "print(\"wood_paper_factor: \", wood_paper_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom dataset class\n",
    "class Top4Dataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, label, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.image_names = os.listdir(root_dir)\n",
    "        self.label = label\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "    \n",
    "    def __items_class__(self):\n",
    "        return self.label\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.image_names[index]\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = read_image(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        image = image.float()\n",
    "        material_name = self.annotations[self.annotations[\"filename\"] == img_name][\"label\"].values[0]\n",
    "        y_label = [0.0, 0.0, 0.0]\n",
    "        y_label[self.label[material_name]] = 1.0\n",
    "        y_label = torch.tensor(y_label)\n",
    "        path = img_name\n",
    "        return (image, y_label, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material_label = {\"metal\": 0, \"plastic\": 1, \"wood,paper\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data transforms\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((144,144)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_label = \"./labels_upsampled.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top4Dataset_train = Top4Dataset(csv_file=csv_file_label, root_dir=target_dir + \"train/\", label=material_label, transform=data_transforms)\n",
    "Top4Dataset_val = Top4Dataset(csv_file=csv_file_label, root_dir=target_dir + \"val/\", label=material_label, transform=data_transforms)\n",
    "Top4Dataset_test = Top4Dataset(csv_file=csv_file_label, root_dir=target_dir + \"test/\", label=material_label, transform=data_transforms)\n",
    "\n",
    "print(f\"length of train dataset: {len(Top4Dataset_train)}\")\n",
    "print(f\"length of val dataset: {len(Top4Dataset_val)}\")\n",
    "print(f\"length of test dataset: {len(Top4Dataset_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_count = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoader_train = DataLoader(dataset=Top4Dataset_train, batch_size=batch_count, shuffle=True)\n",
    "DataLoader_val = DataLoader(dataset=Top4Dataset_val, batch_size=batch_count, shuffle=True)\n",
    "DataLoader_test = DataLoader(dataset=Top4Dataset_test, batch_size=batch_count, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['metal', 'plastic', 'wood,paper']\n",
    "DataLoader_train.dataset.__items_class__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show images\n",
    "data = next(iter(DataLoader_train))\n",
    "images, labels, path = data\n",
    "plt.figure(figsize=(10, 15))\n",
    "for i in range(batch_count):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.imshow(images[i].permute(1, 2, 0))\n",
    "    plt.title(label_list[labels[i].argmax()])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class ConvNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_relu_stack = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool2d(kernel_size=3, stride=3),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool2d(kernel_size=3, stride=3),\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(8192, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = nn.functional.normalize(x)\n",
    "        logits = self.conv_relu_stack(x)\n",
    "        logits = self.flatten(logits)\n",
    "        logits = nn.functional.dropout(logits, p=0.3)\n",
    "        logits = self.linear_relu_stack(logits)\n",
    "        return logits\n",
    "\n",
    "model = ConvNeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    loss_result = 0\n",
    "    for batch, (X, y, path) in enumerate(dataloader):\n",
    "        # add noise to the image\n",
    "        # Compute prediction error\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_result += loss.item()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    return loss_result/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper():\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "        self.losshistory = []\n",
    "        self.trainlosshistory = []\n",
    "\n",
    "    def early_stop(self, validation_loss, train_loss, nnmodel):\n",
    "        self.losshistory.append(validation_loss)\n",
    "        self.trainlosshistory.append(train_loss)\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            torch.save(model.state_dict(), \"model.pt\")\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss >= (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for (X, y, z) in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [metal_factor, plastic_factor, wood_paper_factor]\n",
    "DataLoader_train.dataset.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model parameters\n",
    "learning_rate = 1e-3\n",
    "epochs = 100\n",
    "loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(weight).to(device))\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create early stopper (recall it if you want to reset the training history)\n",
    "early_stopping = EarlyStopper( patience=2, min_delta=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss = train(DataLoader_train, model, loss_fn, optimizer)\n",
    "    test_loss = test(DataLoader_test, model, loss_fn)\n",
    "    print(f\"Train Loss: {train_loss}\")\n",
    "    early_stopping.early_stop(test_loss, train_loss, model)\n",
    "    #if early_stopping.early_stop(test_loss, train_loss, model):\n",
    "        #print(\"Early stopping\")\n",
    "        #break\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(early_stopping.losshistory, label='validation loss')\n",
    "plt.plot(early_stopping.trainlosshistory, label='train loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best model (minimum test loss)\n",
    "model.load_state_dict(torch.load(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    xb = img\n",
    "    xb = transforms.Resize((144,144))(xb)\n",
    "    xb = transforms.ToTensor()(xb)\n",
    "    xb = xb.unsqueeze(0)\n",
    "    xb = xb.to(device)\n",
    "    xb = xb.float()\n",
    "    yb = model(xb)\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(model, path, material_label):\n",
    "    confusion_matrix = torch.zeros(3, 3)\n",
    "    with torch.no_grad():\n",
    "        for file in os.listdir(path):\n",
    "            img_path = file\n",
    "            img = PIL.Image.open(path + img_path)\n",
    "            label = labeling[labeling[\"filename\"] == img_path][\"label\"].values[0]\n",
    "            nr_label = material_label.get(label)\n",
    "            pred = predict_image(img, model)\n",
    "            confusion_matrix[nr_label, pred] += 1\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"./trainvaltest/test/\"\n",
    "val_path = \"./trainvaltest/val/\"\n",
    "train_path = \"./trainvaltest/train/\"\n",
    "test_conf_mat = confusionMatrix(model, test_path, DataLoader_test.dataset.label)\n",
    "val_conf_mat = confusionMatrix(model, val_path, DataLoader_val.dataset.label)\n",
    "train_conf_mat = confusionMatrix(model, train_path, DataLoader_train.dataset.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion matrix\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"Confusion Matrix - Validation Data\")\n",
    "sns.heatmap(val_conf_mat, annot=True, fmt='g', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Confusion Matrix - Test Data\")\n",
    "sns.heatmap(test_conf_mat, annot=True, fmt='g', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"Confusion Matrix - Train Data\")\n",
    "sns.heatmap(train_conf_mat, annot=True, fmt='g', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a71982e2765f6eb6b33820c8a9a4dd21ae31a9aa60cef222f62c4fbc4323d02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
